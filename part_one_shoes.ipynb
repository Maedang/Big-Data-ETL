{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSHoBtRPHO1r",
        "outputId": "fa0cf69d-6af8-4381-d2b4-6c10cdaeeaf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845499 sha256=7d106dfbcbb7e03e41ae8664f09027629bb58d8d75539a1fa840ba0ec187f921\n",
            "  Stored in directory: /Users/maidang/Library/Caches/pip/wheels/51/c8/18/298a4ced8ebb3ab8a7d26a7198c0cc7035abb906bde94a4c4b\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ],
      "source": [
        "! pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8eFW_wl1n39",
        "outputId": "54e701cd-9786-4bcb-f57f-cbc3de451cad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:2 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:10 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 172 kB in 2s (108 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "# Activate Spark in our Colab notebook.\n",
        "import os\n",
        "spark_version = 'spark-3.1.3'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzCrgs0Z1rnw",
        "outputId": "e9e95a8d-1f41-4be0-bae5-76f38df13390"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-15 15:50:34--  https://jdbc.postgresql.org/download/postgresql-42.2.9.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 914037 (893K) [application/java-archive]\n",
            "Saving to: ‘postgresql-42.2.9.jar’\n",
            "\n",
            "postgresql-42.2.9.j 100%[===================>] 892.61K  5.41MB/s    in 0.2s    \n",
            "\n",
            "2023-01-15 15:50:34 (5.41 MB/s) - ‘postgresql-42.2.9.jar’ saved [914037/914037]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get postgresql package\n",
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.9.jar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0DuBth0V2PR8"
      },
      "outputs": [],
      "source": [
        "# Import Spark and create a SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"BigData-HW-1\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.9.jar\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3W2XJVi2CU-"
      },
      "source": [
        "# Extract the Amazon Data into Spark DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na_stw7b1wfU",
        "outputId": "33c3ad7a-2028-47c3-e25b-f481c92cbea1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-------------------+\n",
            "|marketplace|customer_id|     review_id|product_id|product_parent|       product_title|product_category|star_rating|helpful_votes|total_votes|vine|verified_purchase|     review_headline|         review_body|        review_date|\n",
            "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-------------------+\n",
            "|         US|   18069663|R3P2HIOQCIN5ZU|B000XB31C0|     265024781|Minnetonka Men's ...|           Shoes|          1|            0|          0|   N|                Y|                   .|Do not buy: reall...|2015-01-31 00:08:00|\n",
            "|         US|   16251825|R12VVR0WH5Q24V|B00CFYZH5W|     259035853|Teva Men's Pajaro...|           Shoes|          5|            0|          0|   N|                Y|     super flip flop|provides great cu...|2015-01-31 00:08:00|\n",
            "|         US|   20381037| RNCCKB6TV5EEF|B00S8JNN3Q|     666066660|Anne Klein Perfec...|           Shoes|          4|            0|          0|   N|                Y| Great clutch purse!|It's perfect if y...|2015-01-31 00:08:00|\n",
            "|         US|     108364|R2NZXYIVCGB13W|B00XFBPOQG|     448483263|adidas Men's 10K ...|           Shoes|          5|            0|          6|   N|                Y|              Badass|  Getting what u see|2015-01-31 00:08:00|\n",
            "|         US|   45449350|R2EQ1TG9IT3OEQ|B00SW64Y9W|       7853171|OverBling Sneaker...|           Shoes|          3|            0|          0|   N|                Y|         Three Stars|               small|2015-01-31 00:08:00|\n",
            "|         US|   19324665|R1WXA9JSC2H1U1|B011F9E6LI|      14311457|MESSI 15.3 FG/AG ...|           Shoes|          5|            1|          1|   N|                Y|          Five Stars|My 13 year old so...|2015-01-31 00:08:00|\n",
            "|         US|   50073594|R12ENYLFGGNWRV|B00HAUP1OI|     264821602|Hoka One One Men'...|           Shoes|          5|            1|          1|   N|                Y|Finally, some cus...|Ok, I have been s...|2015-01-31 00:08:00|\n",
            "|         US|   21706057|R2R07E5PNXEUO5|B00L1RKOKW|     767118055|Olukai Nohea Mesh...|           Shoes|          4|            0|          0|   N|                Y|good deal, but ha...|I went a full siz...|2015-01-31 00:08:00|\n",
            "|         US|   13708216|R27BA52AKWMWN3|B005WA9MSE|     813856438|Carolina Mens 6\" ...|           Shoes|          5|            0|          0|   N|                Y|... would have to...|I would have to s...|2015-01-31 00:08:00|\n",
            "|         US|   40542649| RLF8DOID2KD5O|B00BEYQI5C|     661491213|Alegria Women's S...|           Shoes|          3|            0|          0|   N|                Y|           Too small|The size is misle...|2015-01-31 00:08:00|\n",
            "|         US|   13409446|R369CEXHXHC6NQ|B00EYAFTCQ|     332158165|Naturalizer Women...|           Shoes|          5|            0|          0|   N|                Y|          Five Stars|These shoes are v...|2015-01-31 00:08:00|\n",
            "|         US|    9451727|R171PPIJXFONVI|B00I0QHY32|      49243908|Forever Link Wome...|           Shoes|          5|            0|          0|   N|                Y|          Five Stars|I love these sand...|2015-01-31 00:08:00|\n",
            "|         US|     193731|R2JDNM8F2P06FU|B010FZZKYA|     161497902|Versace Collectio...|           Shoes|          4|            1|          1|   N|                Y|          Four Stars|Good quality shoe...|2015-01-31 00:08:00|\n",
            "|         US|   34798634|R2W977FO4M97XT|B00V8B30K2|     759958795|Twisted Girl's Ch...|           Shoes|          5|            0|          1|   N|                Y|Good shoes, comfo...|My daughter reall...|2015-01-31 00:08:00|\n",
            "|         US|   37235551|R3AM24QPLI28UY|B00LAVB1TC|     910150896|Travel Smart Hand...|           Shoes|          2|            1|          2|   N|                Y|           Two Stars|         It's okay .|2015-01-31 00:08:00|\n",
            "|         US|   27081399| REDVXSFYVNT5T|B003C1P8B0|     762792587|Saucony Originals...|           Shoes|          5|            0|          0|   N|                Y|    Love these shoes|Love these shoes!...|2015-01-31 00:08:00|\n",
            "|         US|     120678|R14AIIK7D6ENDZ|B000W3UL7W|     123724495|Dr. Marten's Wome...|           Shoes|          5|            0|          0|   N|                Y|          Five Stars|                Good|2015-01-31 00:08:00|\n",
            "|         US|   22272389|R3B1NURKMCVAL1|B00LX65PQO|     848850234|Skechers Performa...|           Shoes|          3|            2|          2|   N|                Y|         Three Stars|I like the go wal...|2015-01-31 00:08:00|\n",
            "|         US|   19584241|R14Q1GZGV10IMX|B00BEE7N3I|     211637196|Hi-Tec Kid's Nepa...|           Shoes|          4|            0|          0|   N|                Y|          Four Stars|Kids love them fo...|2015-01-31 00:08:00|\n",
            "|         US|   12334573| R9BHBB06QD6TM|B008NCHMBW|     138572112|Foot Sox Original...|           Shoes|          1|            2|          2|   N|                Y|Tissue paper is t...|Tissue paper is t...|2015-01-31 00:08:00|\n",
            "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Read in the data from an S3 Bucket\n",
        "from pyspark import SparkFiles\n",
        "url = \"https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Shoes_v1_00.tsv.gz\"\n",
        "spark.sparkContext.addFile(url)\n",
        "\n",
        "df = spark.read.option('header', 'true').csv(SparkFiles.get(\"amazon_reviews_us_Shoes_v1_00.tsv.gz\"), inferSchema=True, sep='\\t', timestampFormat=\"yyyy-mm-dd\")\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cayz-3Q52IM3",
        "outputId": "64bb7f83-a258-4cfd-8de8-84aa37d6e568"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4366916"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Get the number of rows in the DataFrame.\n",
        "df.count()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df= df.dropna()\n",
        "df.count()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYuu_IpuKnPb",
        "outputId": "c526c368-e474-4465-d2e7-1edce5d4ecef"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4366324"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9U0rkGZ2eu7"
      },
      "source": [
        "# Transform the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUoftWoKtM_c"
      },
      "source": [
        "## Create the \"review_id_table\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tMYkSIk2d-m",
        "outputId": "ff2ab045-a72a-46db-8641-4f6b0ef83850"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----------+----------+--------------+-------------------+\n",
            "|     review_id|customer_id|product_id|product_parent|        review_date|\n",
            "+--------------+-----------+----------+--------------+-------------------+\n",
            "|R3P2HIOQCIN5ZU|   18069663|B000XB31C0|     265024781|2015-01-31 00:08:00|\n",
            "|R12VVR0WH5Q24V|   16251825|B00CFYZH5W|     259035853|2015-01-31 00:08:00|\n",
            "| RNCCKB6TV5EEF|   20381037|B00S8JNN3Q|     666066660|2015-01-31 00:08:00|\n",
            "|R2NZXYIVCGB13W|     108364|B00XFBPOQG|     448483263|2015-01-31 00:08:00|\n",
            "|R2EQ1TG9IT3OEQ|   45449350|B00SW64Y9W|       7853171|2015-01-31 00:08:00|\n",
            "|R1WXA9JSC2H1U1|   19324665|B011F9E6LI|      14311457|2015-01-31 00:08:00|\n",
            "|R12ENYLFGGNWRV|   50073594|B00HAUP1OI|     264821602|2015-01-31 00:08:00|\n",
            "|R2R07E5PNXEUO5|   21706057|B00L1RKOKW|     767118055|2015-01-31 00:08:00|\n",
            "|R27BA52AKWMWN3|   13708216|B005WA9MSE|     813856438|2015-01-31 00:08:00|\n",
            "| RLF8DOID2KD5O|   40542649|B00BEYQI5C|     661491213|2015-01-31 00:08:00|\n",
            "|R369CEXHXHC6NQ|   13409446|B00EYAFTCQ|     332158165|2015-01-31 00:08:00|\n",
            "|R171PPIJXFONVI|    9451727|B00I0QHY32|      49243908|2015-01-31 00:08:00|\n",
            "|R2JDNM8F2P06FU|     193731|B010FZZKYA|     161497902|2015-01-31 00:08:00|\n",
            "|R2W977FO4M97XT|   34798634|B00V8B30K2|     759958795|2015-01-31 00:08:00|\n",
            "|R3AM24QPLI28UY|   37235551|B00LAVB1TC|     910150896|2015-01-31 00:08:00|\n",
            "| REDVXSFYVNT5T|   27081399|B003C1P8B0|     762792587|2015-01-31 00:08:00|\n",
            "|R14AIIK7D6ENDZ|     120678|B000W3UL7W|     123724495|2015-01-31 00:08:00|\n",
            "|R3B1NURKMCVAL1|   22272389|B00LX65PQO|     848850234|2015-01-31 00:08:00|\n",
            "|R14Q1GZGV10IMX|   19584241|B00BEE7N3I|     211637196|2015-01-31 00:08:00|\n",
            "| R9BHBB06QD6TM|   12334573|B008NCHMBW|     138572112|2015-01-31 00:08:00|\n",
            "+--------------+-----------+----------+--------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import to_date\n",
        "# Create the \"review_id_df\" DataFrame with the appropriate columns and data types.\n",
        "review_id_df = df.select([\"review_id\",\"customer_id\",\"product_id\", \"product_parent\",\"review_date\"])\n",
        "review_id_df.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print schema\n",
        "review_id_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMbTtJSUMpTH",
        "outputId": "34373103-ac1c-450d-d902-3616819ed319"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- review_id: string (nullable = true)\n",
            " |-- customer_id: integer (nullable = true)\n",
            " |-- product_id: string (nullable = true)\n",
            " |-- product_parent: integer (nullable = true)\n",
            " |-- review_date: timestamp (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAVCFjXhtXO8"
      },
      "source": [
        "## Create the \"products\" Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9gTNhT62je4",
        "outputId": "1c3a9307-c6ef-4737-e58d-19a3c8010a1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+\n",
            "|product_id|       product_title|\n",
            "+----------+--------------------+\n",
            "|B001CJL5ES|L.B. Evans Men's ...|\n",
            "|B002MCVHUQ|New Balance Insol...|\n",
            "|B00UXBFW6S|Kenox Sling Backp...|\n",
            "|B002CMM4M6|Capezio Women's 1...|\n",
            "|B00HNO32BU|Timberland PRO Me...|\n",
            "|B00C6BQQW2|New Balance Men's...|\n",
            "|B00M0NREE0|New Balance Women...|\n",
            "|B00ZC4VIKK|Donalworld Women ...|\n",
            "|B00291CGH8|Justin Boots Wome...|\n",
            "|B000P6GKOO|Nike Men's Rosher...|\n",
            "|B00IEB8BQ2|Khan New 2014 Uni...|\n",
            "|B00IBGJKW4|Powerstep Ultrast...|\n",
            "|B008KK1D5S|Clarks Women's Br...|\n",
            "|B003IHV9XE|Birkenstock Women...|\n",
            "|B00M9500FY|FitFlop Women's L...|\n",
            "|B00R59ZBXU|Keds Women's Doub...|\n",
            "|B00KQ66NBS|New Balance Men's...|\n",
            "|B00E41QYRE|Jambu Women's Xte...|\n",
            "|B0106QF79Q|Sanita Women's Pr...|\n",
            "|B0084ZF7V0|DV by Dolce Vita ...|\n",
            "+----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create the \"products_df\" DataFrame that drops the duplicates in the \"product_id\" and \"product_title columns. \n",
        "products_df = df.select([\"product_id\",\"product_title\"])\n",
        "products_df = products_df.dropDuplicates()\n",
        "products_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJHuZ9zut0e5"
      },
      "source": [
        "## Create the \"customers\" Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pF2Vf3c2n2O",
        "outputId": "ba7cdf8f-0845-4047-afeb-dbb2141e45b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------+\n",
            "|customer_id|customer_count|\n",
            "+-----------+--------------+\n",
            "|   45547332|           210|\n",
            "|    2761437|           196|\n",
            "|   52433525|           171|\n",
            "|   12228192|           161|\n",
            "|   20872710|           152|\n",
            "|   41287822|           150|\n",
            "|   52761203|           125|\n",
            "|   13199159|           124|\n",
            "|    8118847|           113|\n",
            "|   11820781|           107|\n",
            "|   52166867|           104|\n",
            "|   10065681|           104|\n",
            "|   29295120|           101|\n",
            "|   25652896|           100|\n",
            "|   25588663|            98|\n",
            "|   35921152|            92|\n",
            "|   45393130|            90|\n",
            "|   13925291|            89|\n",
            "|   27635773|            88|\n",
            "|   10900104|            87|\n",
            "+-----------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create the \"customers_df\" DataFrame that groups the data on the \"customer_id\" by the number of times a customer reviewed a product. \n",
        "# Load in a sql function to use columns\n",
        "from pyspark.sql.functions import desc\n",
        "customers_df = df.groupby(\"customer_id\").agg({\"customer_id\":\"count\"})\n",
        "customers_df = customers_df.orderBy(desc(\"count(customer_id)\"))\n",
        "customers_df = customers_df.withColumnRenamed(\"count(customer_id)\", \"customer_count\") \n",
        "customers_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SbTasxbuXGK"
      },
      "source": [
        "## Create the \"vine_table\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHQKbmCE2p3Q",
        "outputId": "e4925943-3c1e-4844-8fec-3cd9d28414de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----------+-------------+-----------+----+\n",
            "|     review_id|star_rating|helpful_votes|total_votes|vine|\n",
            "+--------------+-----------+-------------+-----------+----+\n",
            "|R3P2HIOQCIN5ZU|          1|            0|          0|   N|\n",
            "|R12VVR0WH5Q24V|          5|            0|          0|   N|\n",
            "| RNCCKB6TV5EEF|          4|            0|          0|   N|\n",
            "|R2NZXYIVCGB13W|          5|            0|          6|   N|\n",
            "|R2EQ1TG9IT3OEQ|          3|            0|          0|   N|\n",
            "|R1WXA9JSC2H1U1|          5|            1|          1|   N|\n",
            "|R12ENYLFGGNWRV|          5|            1|          1|   N|\n",
            "|R2R07E5PNXEUO5|          4|            0|          0|   N|\n",
            "|R27BA52AKWMWN3|          5|            0|          0|   N|\n",
            "| RLF8DOID2KD5O|          3|            0|          0|   N|\n",
            "|R369CEXHXHC6NQ|          5|            0|          0|   N|\n",
            "|R171PPIJXFONVI|          5|            0|          0|   N|\n",
            "|R2JDNM8F2P06FU|          4|            1|          1|   N|\n",
            "|R2W977FO4M97XT|          5|            0|          1|   N|\n",
            "|R3AM24QPLI28UY|          2|            1|          2|   N|\n",
            "| REDVXSFYVNT5T|          5|            0|          0|   N|\n",
            "|R14AIIK7D6ENDZ|          5|            0|          0|   N|\n",
            "|R3B1NURKMCVAL1|          3|            2|          2|   N|\n",
            "|R14Q1GZGV10IMX|          4|            0|          0|   N|\n",
            "| R9BHBB06QD6TM|          1|            2|          2|   N|\n",
            "+--------------+-----------+-------------+-----------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create the \"vine_df\" DataFrame that has the \"review_id\", \"star_rating\", \"helpful_votes\", \"total_votes\", and \"vine\" columns. \n",
        "# Load in a sql function to use columns\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "vine_table_df = df.select([\"review_id\",\"star_rating\",\"helpful_votes\", \"total_votes\",\"vine\"])\n",
        "\n",
        "# # Filter for only columns from Amazon's Vine program\n",
        "# vine_table_df = vine_table_df.filter(col(\"vine\")  == \"Y\")\n",
        "vine_table_df.show() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8aTsEjZ2s6L"
      },
      "source": [
        "# Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "W4dzUKfI2vXM"
      },
      "outputs": [],
      "source": [
        "mode = \"append\"\n",
        "jdbc_url=\"jdbc:postgresql://<endpoint>:5432/my_data_class_db\"\n",
        "config = {\"user\":\"postgres\", \n",
        "          \"password\": \"<password>\", \n",
        "          \"driver\":\"org.postgresql.Driver\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "iOxKqMsD2yVs"
      },
      "outputs": [],
      "source": [
        "# Write products_df to table in RDS\n",
        "products_df.write.jdbc(url=jdbc_url, table='products', mode=mode, properties=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "aHbca4zN2yIa"
      },
      "outputs": [],
      "source": [
        "# Write customers_df to table in RDS\n",
        "customers_df.write.jdbc(url=jdbc_url, table='customers', mode=mode, properties=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "2HfOFneW2x_F"
      },
      "outputs": [],
      "source": [
        "# Write vine_df to table in RDS\n",
        "vine_table_df.write.jdbc(url=jdbc_url, table='vine_table', mode=mode, properties=config)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}